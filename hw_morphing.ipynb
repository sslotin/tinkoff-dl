{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как пишут сети в 2к18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(train, batch_size):\n",
    "    dataset = datasets.MNIST('mnist', train=train, download=True,\n",
    "        transform=transforms.ToTensor())\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "    \n",
    "train = get_loader(True, 64)\n",
    "val = get_loader(False, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, ???),\n",
    "    # ...\n",
    "    nn.SoftMax()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "criterion = torch.nn.NLLLoss()\n",
    "# ^ попробуйте какой-нибудь другой, если не уверовали в кроссэнтропию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "for epoch in range(20):\n",
    "    for X, y in train:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(X)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    plt.plot(train_losses)\n",
    "    plt.show()\n",
    "    \n",
    "    # как-нибудь сами посчитайте валидацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте здесь уже напишем небольшой класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encode = nn.Sequential(\n",
    "            # ...\n",
    "        )\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            # ...\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "model = Autoencoder()\n",
    "criterion = MSEloss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss = 0\n",
    "    for data, _ in dataloader:\n",
    "        #     ^ лэйблы нам не нужны\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        reconstructed = model(data)\n",
    "        loss = criterial(data, reconstructed)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch %d, loss %.4f' % (epoch, train_loss / len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анимации `matplotlib` — это жесть. Не разбирайтесь в коде внизу, он просто нужен для плавных визуализаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('mnist', train=train, download=True,\n",
    "        transform=transforms.ToTensor())\n",
    "\n",
    "def get(x):\n",
    "    return dataset[x][0][0]\n",
    "\n",
    "def imshow(img):\n",
    "    pic = img.numpy().astype('float')\n",
    "    plt.axis('off')\n",
    "    return plt.imshow(pic, cmap='Greys', animated=True)\n",
    "\n",
    "def morph(inputs, steps, delay):\n",
    "    latent = [model.encode(get(k)) for k in inputs]\n",
    "    fig = plt.figure()\n",
    "    images = []\n",
    "    for a, b in zip(inputs, inputs[1:] + [inputs[0]]):\n",
    "        for t in np.linspace(0, 1, steps):\n",
    "            c = a*(1-t)+b*t\n",
    "            morphed = model.decode(c).data.view(28, 28)\n",
    "            images.append([imshow(morphed)])\n",
    "    \n",
    "    ani = animation.ArtistAnimation(fig, images, interval=delay)\n",
    "\n",
    "    display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph(np.randint(len(dataset), 10), 20, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
